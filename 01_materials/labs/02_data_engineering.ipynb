{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACLOCAL_PATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\aclocal;C:\\\\Program Files\\\\Git\\\\usr\\\\share\\\\aclocal',\n",
       " 'ALLUSERSPROFILE': 'C:\\\\ProgramData',\n",
       " 'APPDATA': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Roaming',\n",
       " 'CHROME_CRASHPAD_PIPE_NAME': '\\\\\\\\.\\\\pipe\\\\crashpad_15832_PSRFJSKEAPAJOMHO',\n",
       " 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files',\n",
       " 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMPUTERNAME': 'HUHU-SURFACE',\n",
       " 'COMSPEC': 'C:\\\\windows\\\\system32\\\\cmd.exe',\n",
       " 'CONDA_DEFAULT_ENV': 'dsi_participant',\n",
       " 'CONDA_EXE': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\condabin\\\\..\\\\Scripts\\\\conda.exe',\n",
       " 'CONDA_EXES': '\"C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\condabin\\\\..\\\\Scripts\\\\conda.exe\"  ',\n",
       " 'CONDA_PREFIX': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant',\n",
       " 'CONDA_PROMPT_MODIFIER': '(dsi_participant) ',\n",
       " 'CONDA_PYTHON_EXE': 'C:/Users/hyunh/AppData/Local/miniconda/python.exe',\n",
       " 'CONDA_ROOT': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda',\n",
       " 'CONDA_SHLVL': '1',\n",
       " 'CONFIG_SITE': 'C:/Program Files/Git/etc/config.site',\n",
       " 'DISPLAY': 'needs-to-be-defined',\n",
       " 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData',\n",
       " 'ELECTRON_NO_ATTACH_CONSOLE': '1',\n",
       " 'ELECTRON_RUN_AS_NODE': '1',\n",
       " 'EXEPATH': 'C:\\\\Program Files\\\\Git',\n",
       " 'HOME': 'C:\\\\Users',\n",
       " 'HOMEDRIVE': 'C:',\n",
       " 'HOMEPATH': '\\\\Users\\\\hyunh',\n",
       " 'HOSTNAME': 'Huhu-Surface',\n",
       " 'INFOPATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\local\\\\info;C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\info;C:\\\\Program Files\\\\Git\\\\usr\\\\local\\\\info;C:\\\\Program Files\\\\Git\\\\usr\\\\share\\\\info;C:\\\\Program Files\\\\Git\\\\usr\\\\info;C:\\\\Program Files\\\\Git\\\\share\\\\info',\n",
       " 'JAVA_HOME': 'C:\\\\Users\\\\hyunh\\\\.jdks\\\\openjdk-22.0.1',\n",
       " 'JPY_INTERRUPT_EVENT': '1856',\n",
       " 'LC_CTYPE': 'en_US.UTF-8',\n",
       " 'LOCALAPPDATA': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Local',\n",
       " 'LOGONSERVER': '\\\\\\\\HUHU-SURFACE',\n",
       " 'MANPATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\local\\\\man;C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\man;C:\\\\Program Files\\\\Git\\\\usr\\\\local\\\\man;C:\\\\Program Files\\\\Git\\\\usr\\\\share\\\\man;C:\\\\Program Files\\\\Git\\\\usr\\\\man;C:\\\\Program Files\\\\Git\\\\share\\\\man',\n",
       " 'MINGW_CHOST': 'x86_64-w64-mingw32',\n",
       " 'MINGW_PACKAGE_PREFIX': 'mingw-w64-x86_64',\n",
       " 'MINGW_PREFIX': 'C:/Program Files/Git/mingw64',\n",
       " 'MSYS': 'disable_pcon',\n",
       " 'MSYSTEM': 'MINGW64',\n",
       " 'MSYSTEM_CARCH': 'x86_64',\n",
       " 'MSYSTEM_CHOST': 'x86_64-w64-mingw32',\n",
       " 'MSYSTEM_PREFIX': 'C:/Program Files/Git/mingw64',\n",
       " 'NODE_TLS_REJECT_UNAUTHORIZED': 'undefined',\n",
       " 'NUMBER_OF_PROCESSORS': '8',\n",
       " 'OLDPWD': 'C:/Users/hyunh/OneDrive',\n",
       " 'ONEDRIVE': 'C:\\\\Users\\\\hyunh\\\\OneDrive - Universiteit Utrecht',\n",
       " 'ONEDRIVECOMMERCIAL': 'C:\\\\Users\\\\hyunh\\\\OneDrive - Universiteit Utrecht',\n",
       " 'ONEDRIVECONSUMER': 'C:\\\\Users\\\\hyunh\\\\OneDrive',\n",
       " 'ORIGINAL_PATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Users\\\\bin;C:\\\\Program Files\\\\ImageMagick-7.1.0-Q16-HDRI;C:\\\\windows\\\\system32;C:\\\\windows;C:\\\\windows\\\\System32\\\\Wbem;C:\\\\windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\windows\\\\System32\\\\OpenSSH;C:\\\\Users\\\\hyunh\\\\.jdks\\\\openjdk-22.0.1\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\nodejs;C:\\\\Program Files\\\\MySQL\\\\MySQL Shell 8.0\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Library\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Scripts;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Roaming\\\\npm;C:\\\\Program Files\\\\MySQL\\\\MySQL Server 8.0\\\\bin',\n",
       " 'ORIGINAL_TEMP': 'C:/Users/hyunh/AppData/Local/Temp',\n",
       " 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined',\n",
       " 'OS': 'Windows_NT',\n",
       " 'PATH': 'c:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant\\\\Library\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant\\\\Scripts;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\envs\\\\dsi_participant\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\condabin;C:\\\\Users\\\\bin;C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\local\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Users\\\\bin;C:\\\\Program Files\\\\ImageMagick-7.1.0-Q16-HDRI;C:\\\\windows\\\\system32;C:\\\\windows;C:\\\\windows\\\\System32\\\\Wbem;C:\\\\windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\windows\\\\System32\\\\OpenSSH;C:\\\\Users\\\\hyunh\\\\.jdks\\\\openjdk-22.0.1\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\nodejs;C:\\\\Program Files\\\\MySQL\\\\MySQL Shell 8.0\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Library\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\miniconda\\\\Scripts;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\hyunh\\\\AppData\\\\Roaming\\\\npm;C:\\\\Program Files\\\\MySQL\\\\MySQL Server 8.0\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\vendor_perl;C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\core_perl',\n",
       " 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC',\n",
       " 'PKG_CONFIG_PATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\lib\\\\pkgconfig;C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\pkgconfig',\n",
       " 'PKG_CONFIG_SYSTEM_INCLUDE_PATH': 'C:/Program Files/Git/mingw64/include',\n",
       " 'PKG_CONFIG_SYSTEM_LIBRARY_PATH': 'C:/Program Files/Git/mingw64/lib',\n",
       " 'PLINK_PROTOCOL': 'ssh',\n",
       " 'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
       " 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 126 Stepping 5, GenuineIntel',\n",
       " 'PROCESSOR_LEVEL': '6',\n",
       " 'PROCESSOR_REVISION': '7e05',\n",
       " 'PROGRAMDATA': 'C:\\\\ProgramData',\n",
       " 'PROGRAMFILES': 'C:\\\\Program Files',\n",
       " 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)',\n",
       " 'PROGRAMW6432': 'C:\\\\Program Files',\n",
       " 'PROMPT': '(dsi_participant) $P$G',\n",
       " 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules',\n",
       " 'PUBLIC': 'C:\\\\Users\\\\Public',\n",
       " 'PWD': 'C:/Users/hyunh/OneDrive/UofT_DSI',\n",
       " 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1',\n",
       " 'PYTHONIOENCODING': 'utf-8',\n",
       " 'PYTHONUNBUFFERED': '1',\n",
       " 'PYTHONUTF8': '1',\n",
       " 'PYTHON_FROZEN_MODULES': 'on',\n",
       " 'SHELL': 'C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\bash.exe',\n",
       " 'SHLVL': '2',\n",
       " 'SSH_ASKPASS': 'C:/Program Files/Git/mingw64/bin/git-askpass.exe',\n",
       " 'SYSTEMDRIVE': 'C:',\n",
       " 'SYSTEMROOT': 'C:\\\\windows',\n",
       " 'TEMP': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Local\\\\Temp',\n",
       " 'TERM': 'xterm-color',\n",
       " 'TERM_PROGRAM': 'mintty',\n",
       " 'TERM_PROGRAM_VERSION': '3.7.4',\n",
       " 'USERDOMAIN': 'HUHU-SURFACE',\n",
       " 'USERDOMAIN_ROAMINGPROFILE': 'HUHU-SURFACE',\n",
       " 'USERNAME': 'hyunh',\n",
       " 'USERPROFILE': 'C:\\\\Users\\\\hyunh',\n",
       " 'VSCODE_CLI': '1',\n",
       " 'VSCODE_CODE_CACHE_PATH': 'C:\\\\Users\\\\hyunh\\\\AppData\\\\Roaming\\\\Code\\\\CachedData\\\\91fbdddc47bc9c09064bf7acf133d22631cbf083',\n",
       " 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost',\n",
       " 'VSCODE_CWD': 'C:\\\\Users\\\\hyunh\\\\OneDrive\\\\UofT_DSI',\n",
       " 'VSCODE_ESM_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess',\n",
       " 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true',\n",
       " 'VSCODE_IPC_HOOK': '\\\\\\\\.\\\\pipe\\\\8da9bcec-1.96.3-main-sock',\n",
       " 'VSCODE_L10N_BUNDLE_LOCATION': '',\n",
       " 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en-us\",\"osLocale\":\"en-us\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"C:\\\\\\\\Users\\\\\\\\hyunh\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Microsoft VS Code\\\\\\\\resources\\\\\\\\app\\\\\\\\out\\\\\\\\nls.messages.json\",\"locale\":\"en-us\",\"availableLanguages\":{}}',\n",
       " 'VSCODE_PID': '15832',\n",
       " 'WINDIR': 'C:\\\\windows',\n",
       " 'XML_CATALOG_FILES': 'file:///C:/Users/hyunh/AppData/Local/miniconda/envs/dsi_participant/etc/xml/catalog',\n",
       " '_': 'C:/Users/hyunh/AppData/Local/Programs/Microsoft VS Code/Code.exe',\n",
       " '_CONDA_OLD_CHCP': '437',\n",
       " '__COMPAT_LAYER': 'RunAsAdmin',\n",
       " '__PSLOCKDOWNPOLICY': '0',\n",
       " 'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       " 'CLICOLOR': '1',\n",
       " 'FORCE_COLOR': '1',\n",
       " 'CLICOLOR_FORCE': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       " 'LOG_DIR': '../../07_logs/',\n",
       " 'LOG_LEVEL': 'INFO',\n",
       " 'TICKERS': '../../05_src/data/tickers/sp500_wiki.csv',\n",
       " 'TEMP_DATA': '../../05_src/data/temp/',\n",
       " 'SRC_DIR': '../../05_src/',\n",
       " 'PRICE_DATA': '../../05_src/data/prices/',\n",
       " 'FEATURES_DATA': '../../05_src/data/features/stock_features.parquet',\n",
       " 'FEATURES_DATA_2': '../../05_src/data/features/features_assignment.parquet',\n",
       " 'DB_URL': 'postgresql://postgres:HumanAfterAll@localhost:5432/model_db',\n",
       " 'ARTIFACTS_DIR': '../../05_src/data/artifacts/',\n",
       " 'CREDIT_DATA': '../../05_src/data/credit/cs-training.csv',\n",
       " 'LOGISTIC_REGRESSION_PG': '../../05_src/config/logistic_regression_pg.json',\n",
       " 'SVM_PG': '../../05_src/config/svm_pg.json'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv \n",
    "%env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives \n",
    "\n",
    "\n",
    "* Build a data pipeline that downloads price data from the internet, stores it locally, transforms it into return data, and stores the feature set.\n",
    "    - Getting the data.\n",
    "    - Schemas and index in dask.\n",
    "\n",
    "* Explore the parquet format.\n",
    "    - Reading and writing parquet files.\n",
    "    - Read datasets that are stored in distributed files.\n",
    "    - Discuss dask vs pandas as a small example of big vs small data.\n",
    "    \n",
    "* Discuss the use of environment variables for settings.\n",
    "* Discuss how to use Jupyter notebooks and source code concurrently. \n",
    "* Logging and using a standard logger.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "+ We will download the prices for a list of stocks.\n",
    "+ The source is Yahoo Finance and we will use the API provided by the library yfinance.\n",
    "\n",
    "\n",
    "## Medallion Architecture\n",
    "\n",
    "+ The architecture that we are thinking about is called Medallion by [DataBricks](https://www.databricks.com/glossary/medallion-architecture). It is an ELT type of thinking, although our data is well-structured.\n",
    "\n",
    "![Medallion Architecture (DataBicks)](./images/02_medallion_architecture.png)\n",
    "\n",
    "+ In our case, we would like to optimize the number of times that we download data from the internet. \n",
    "+ Ultimately, we will build a pipeline manager class that will help us control the process of obtaining and transforming our data.\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from Yahoo Finance\n",
    "\n",
    "Yahoo Finance provides information about public stocks in different markets. The library yfinance gives us access to a fair bit of the data in Yahoo Finance. \n",
    "\n",
    "These steps are based on the instructions in:\n",
    "\n",
    "+ [yfinance documentation](https://pypi.org/project/yfinance/)\n",
    "+ [Tutorial in geeksforgeeks.org](https://www.geeksforgeeks.org/get-financial-data-from-yahoo-finance-with-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If required, install: `python -m pip install yfinance`.\n",
    "+ To download the price history of a stock, first use the following setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getenv('SRC_DIR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice in the code chunk above:\n",
    "\n",
    "+ Libraries are ordered from high-level to low-level libraries from the package manager (pip in this case, but could be conda, poetry, etc.)\n",
    "+ The command `sys.path.append(\"../05_src/)` will add the `../05_src/` directory to the path in the Notebook's kernel. This way, we can use our modules as part of the notebook.\n",
    "+ Local modules are imported at the end. \n",
    "+ The function `get_logger()` is called with `__name__` as recommended by the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to download the historical price data for a stock, we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-02</th>\n",
       "      <td>19.928572</td>\n",
       "      <td>20.154642</td>\n",
       "      <td>19.672144</td>\n",
       "      <td>19.686787</td>\n",
       "      <td>17.175095</td>\n",
       "      <td>472544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>19.939285</td>\n",
       "      <td>20.227858</td>\n",
       "      <td>19.917143</td>\n",
       "      <td>20.225714</td>\n",
       "      <td>17.645269</td>\n",
       "      <td>450968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04</th>\n",
       "      <td>20.196428</td>\n",
       "      <td>20.328215</td>\n",
       "      <td>20.029285</td>\n",
       "      <td>20.178572</td>\n",
       "      <td>17.604143</td>\n",
       "      <td>377809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05</th>\n",
       "      <td>20.451786</td>\n",
       "      <td>20.540714</td>\n",
       "      <td>20.228930</td>\n",
       "      <td>20.282143</td>\n",
       "      <td>17.694490</td>\n",
       "      <td>447580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06</th>\n",
       "      <td>20.206785</td>\n",
       "      <td>20.241072</td>\n",
       "      <td>19.984644</td>\n",
       "      <td>20.000713</td>\n",
       "      <td>17.448973</td>\n",
       "      <td>344352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>195.220001</td>\n",
       "      <td>196.270004</td>\n",
       "      <td>193.110001</td>\n",
       "      <td>194.169998</td>\n",
       "      <td>193.223404</td>\n",
       "      <td>54822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>194.270004</td>\n",
       "      <td>194.759995</td>\n",
       "      <td>191.940002</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>191.481934</td>\n",
       "      <td>44594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>192.009995</td>\n",
       "      <td>192.199997</td>\n",
       "      <td>189.580002</td>\n",
       "      <td>191.729996</td>\n",
       "      <td>190.795273</td>\n",
       "      <td>47145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>190.940002</td>\n",
       "      <td>191.800003</td>\n",
       "      <td>187.470001</td>\n",
       "      <td>188.039993</td>\n",
       "      <td>187.123260</td>\n",
       "      <td>55859400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>187.039993</td>\n",
       "      <td>187.100006</td>\n",
       "      <td>184.350006</td>\n",
       "      <td>184.399994</td>\n",
       "      <td>183.501022</td>\n",
       "      <td>55467800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2013-12-02   19.928572   20.154642   19.672144   19.686787   17.175095   \n",
       "2013-12-03   19.939285   20.227858   19.917143   20.225714   17.645269   \n",
       "2013-12-04   20.196428   20.328215   20.029285   20.178572   17.604143   \n",
       "2013-12-05   20.451786   20.540714   20.228930   20.282143   17.694490   \n",
       "2013-12-06   20.206785   20.241072   19.984644   20.000713   17.448973   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-01-25  195.220001  196.270004  193.110001  194.169998  193.223404   \n",
       "2024-01-26  194.270004  194.759995  191.940002  192.419998  191.481934   \n",
       "2024-01-29  192.009995  192.199997  189.580002  191.729996  190.795273   \n",
       "2024-01-30  190.940002  191.800003  187.470001  188.039993  187.123260   \n",
       "2024-01-31  187.039993  187.100006  184.350006  184.399994  183.501022   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2013-12-02  472544800  \n",
       "2013-12-03  450968000  \n",
       "2013-12-04  377809600  \n",
       "2013-12-05  447580000  \n",
       "2013-12-06  344352400  \n",
       "...               ...  \n",
       "2024-01-25   54822100  \n",
       "2024-01-26   44594000  \n",
       "2024-01-29   47145600  \n",
       "2024-01-30   55859400  \n",
       "2024-01-31   55467800  \n",
       "\n",
       "[2558 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = yf.download('AAPL', start = \"2013-12-01\", end = \"2024-02-01\")\n",
    "px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrize the download\n",
    "\n",
    "+ Generally, we will look to separate every parameter and setting from functions.\n",
    "+ If we had a few stocks, we could cycle through them. We need a place to store the list of tickers (a db or file, for example).\n",
    "+ Store a csv file with a few stock tickers. The location of the file is a setting, the contents of this file are parameters.\n",
    "+ Use **environment variables** to pass parameters.\n",
    "\n",
    "Start by getting a sample of Information Technology stock tickers by applying subindexing and converting the \"ticker\" column from a pandas object to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all tickers\n",
    "ticker_file = os.getenv(\"TICKERS\")\n",
    "tickers = pd.read_csv(ticker_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subset our ticker data set using standard indexing techniques. A good reference for this type of data manipulation is Panda's [Documentation](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing-and-selecting-data) and [Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html#cookbook-selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tech = tickers['GICS Sector'] == 'Information Technology'\n",
    "tech_sector = tickers[idx_tech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the subset data frame, select one column and convert to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_tickers = tech_sector['ticker'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  64 of 64 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                     Adj Close                                      \\\n",
      "Ticker                         AAPL ACN       ADBE        ADI      ADSK   \n",
      "Date                                                                      \n",
      "2000-01-03 00:00:00+00:00  0.843077 NaN  16.274672  28.095686  8.052908   \n",
      "2000-01-04 00:00:00+00:00  0.771996 NaN  14.909399  26.674364  7.660817   \n",
      "2000-01-05 00:00:00+00:00  0.783293 NaN  15.204171  27.063757  7.178245   \n",
      "2000-01-06 00:00:00+00:00  0.715509 NaN  15.328289  26.323883  6.740916   \n",
      "2000-01-07 00:00:00+00:00  0.749401 NaN  16.072985  27.063757  7.540174   \n",
      "\n",
      "Price                                                                 ...  \\\n",
      "Ticker                        AKAM       AMAT     AMD ANET      ANSS  ...   \n",
      "Date                                                                  ...   \n",
      "2000-01-03 00:00:00+00:00  321.250  23.138016  15.500  NaN  2.765625  ...   \n",
      "2000-01-04 00:00:00+00:00  300.000  21.994833  14.625  NaN  2.687500  ...   \n",
      "2000-01-05 00:00:00+00:00  283.500  21.171745  15.000  NaN  2.703125  ...   \n",
      "2000-01-06 00:00:00+00:00  236.125  21.206038  16.000  NaN  2.703125  ...   \n",
      "2000-01-07 00:00:00+00:00  248.375  21.388954  16.250  NaN  2.703125  ...   \n",
      "\n",
      "Price                      Volume                                          \\\n",
      "Ticker                       SWKS     TDY TEL      TER     TRMB       TXN   \n",
      "Date                                                                        \n",
      "2000-01-03 00:00:00+00:00  512000  315400 NaN  1353500  8025000  10815600   \n",
      "2000-01-04 00:00:00+00:00  292600  444300 NaN  1611800  4963200   7952400   \n",
      "2000-01-05 00:00:00+00:00  411800  109100 NaN  1855800  1930200  12142400   \n",
      "2000-01-06 00:00:00+00:00  385400  120700 NaN   964700  2230800  11758400   \n",
      "2000-01-07 00:00:00+00:00  536000  222100 NaN   809200  2166600  12938800   \n",
      "\n",
      "Price                                                         \n",
      "Ticker                        TYL     VRSN      WDC     ZBRA  \n",
      "Date                                                          \n",
      "2000-01-03 00:00:00+00:00  138300  2270100  2461900  1055700  \n",
      "2000-01-04 00:00:00+00:00  135100  3002200  7660300   522450  \n",
      "2000-01-05 00:00:00+00:00  187200  6886600  3944600   612225  \n",
      "2000-01-06 00:00:00+00:00  107200  4003200  2468400   263925  \n",
      "2000-01-07 00:00:00+00:00   78900  3803200  9783000   333900  \n",
      "\n",
      "[5 rows x 384 columns]\n"
     ]
    }
   ],
   "source": [
    "tech_raw_dt = yf.download(tech_tickers, start = \"2000-01-01\", end = \"2025-01-26\")\n",
    "print(tech_raw_dt.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we downloaded combines several stocks and prices into a single row. We want to parse this arrangement into a dataframe that contains observations about a single stock on a given day per row. To do this, we can use the function [`stack()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html) and re-arrange the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>535796800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ACN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>16.274672</td>\n",
       "      <td>16.390625</td>\n",
       "      <td>16.875000</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>16.812500</td>\n",
       "      <td>7384400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ADI</td>\n",
       "      <td>28.095686</td>\n",
       "      <td>45.093750</td>\n",
       "      <td>46.937500</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>3655600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ADSK</td>\n",
       "      <td>8.052908</td>\n",
       "      <td>8.343750</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>8.031250</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2845600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403451</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>TXN</td>\n",
       "      <td>184.158173</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>191.500000</td>\n",
       "      <td>185.029999</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>15856600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403452</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>TYL</td>\n",
       "      <td>591.929993</td>\n",
       "      <td>591.929993</td>\n",
       "      <td>594.969971</td>\n",
       "      <td>590.210022</td>\n",
       "      <td>591.400024</td>\n",
       "      <td>155300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403453</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>VRSN</td>\n",
       "      <td>210.729996</td>\n",
       "      <td>210.729996</td>\n",
       "      <td>210.880005</td>\n",
       "      <td>206.009995</td>\n",
       "      <td>206.020004</td>\n",
       "      <td>563300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403454</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>WDC</td>\n",
       "      <td>67.410004</td>\n",
       "      <td>67.410004</td>\n",
       "      <td>69.440002</td>\n",
       "      <td>67.360001</td>\n",
       "      <td>68.910004</td>\n",
       "      <td>6046500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403455</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>420.079987</td>\n",
       "      <td>413.739990</td>\n",
       "      <td>419.059998</td>\n",
       "      <td>258900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403456 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                       Date Ticker   Adj Close       Close        High  \\\n",
       "0      2000-01-03 00:00:00+00:00   AAPL    0.843077    0.999442    1.004464   \n",
       "1      2000-01-03 00:00:00+00:00    ACN         NaN         NaN         NaN   \n",
       "2      2000-01-03 00:00:00+00:00   ADBE   16.274672   16.390625   16.875000   \n",
       "3      2000-01-03 00:00:00+00:00    ADI   28.095686   45.093750   46.937500   \n",
       "4      2000-01-03 00:00:00+00:00   ADSK    8.052908    8.343750    8.656250   \n",
       "...                          ...    ...         ...         ...         ...   \n",
       "403451 2025-01-24 00:00:00+00:00    TXN  184.158173  185.520004  191.500000   \n",
       "403452 2025-01-24 00:00:00+00:00    TYL  591.929993  591.929993  594.969971   \n",
       "403453 2025-01-24 00:00:00+00:00   VRSN  210.729996  210.729996  210.880005   \n",
       "403454 2025-01-24 00:00:00+00:00    WDC   67.410004   67.410004   69.440002   \n",
       "403455 2025-01-24 00:00:00+00:00   ZBRA  414.609985  414.609985  420.079987   \n",
       "\n",
       "Price          Low        Open       Volume  \n",
       "0         0.907924    0.936384  535796800.0  \n",
       "1              NaN         NaN          NaN  \n",
       "2        16.062500   16.812500    7384400.0  \n",
       "3        44.000000   46.750000    3655600.0  \n",
       "4         8.031250    8.500000    2845600.0  \n",
       "...            ...         ...          ...  \n",
       "403451  185.029999  190.000000   15856600.0  \n",
       "403452  590.210022  591.400024     155300.0  \n",
       "403453  206.009995  206.020004     563300.0  \n",
       "403454   67.360001   68.910004    6046500.0  \n",
       "403455  413.739990  419.059998     258900.0  \n",
       "\n",
       "[403456 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, check what tech_raw_dt.stack() looks like.\n",
    "tech_raw_dt.stack(future_stack=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_dt = (tech_raw_dt\n",
    "           .stack(future_stack=True)\n",
    "           .reset_index()\n",
    "           .sort_values(['Ticker', 'Date']))\n",
    "tech_dt.columns.name = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data in CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have some data. How do we store it?\n",
    "+ We can compare two options, CSV and Parqruet, by measuring their performance:\n",
    "\n",
    "    - Time to save.\n",
    "    - Space required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(path='.'):\n",
    "    '''Returns the total size of files contained in path.'''\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.getenv(\"TEMP_DATA\")\n",
    "os.makedirs(temp, exist_ok=True)\n",
    "stock_path = os.path.join(temp, \"stock_px.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to dt ((403456, 8))csv took 4.96988582611084 seconds.\n",
      "Csv file size 47.817805 MB\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tech_dt.to_csv(stock_path, index = False)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing to dt ({tech_dt.shape})csv took {end - start} seconds.')\n",
    "print(f'Csv file size { os.path.getsize(stock_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Parquet\n",
    "\n",
    "### Dask \n",
    "\n",
    "We can work with with large data sets and parquet files. In fact, recent versions of pandas support pyarrow data types and future versions will require a pyarrow backend. The pyarrow library is an interface between Python and the Appache Arrow project. The [parquet data format](https://parquet.apache.org/) and [Arrow](https://arrow.apache.org/docs/python/parquet.html) are projects of the Apache Foundation.\n",
    "\n",
    "However, Dask is much more than an interface to Arrow: Dask provides parallel and distributed computing on pandas-like dataframes. It is also relatively easy to use, bridging a gap between pandas and Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyunh\\AppData\\Local\\miniconda\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hyunh\\AppData\\Local\\Temp\\ipykernel_19248\\676544213.py:1: DeprecationWarning: The current Dask DataFrame implementation is deprecated. \n",
      "In a future release, Dask DataFrame will use new implementation that\n",
      "contains several improvements including a logical query planning.\n",
      "The user-facing DataFrame API will remain unchanged.\n",
      "\n",
      "The new implementation is already available and can be enabled by\n",
      "installing the dask-expr library:\n",
      "\n",
      "    $ pip install dask-expr\n",
      "\n",
      "and turning the query planning option on:\n",
      "\n",
      "    >>> import dask\n",
      "    >>> dask.config.set({'dataframe.query-planning': True})\n",
      "    >>> import dask.dataframe as dd\n",
      "\n",
      "API documentation for the new implementation is available at\n",
      "https://docs.dask.org/en/stable/dask-expr-api.html\n",
      "\n",
      "Any feedback can be reported on the Dask issue tracker\n",
      "https://github.com/dask/dask/issues \n",
      "\n",
      "  import dask.dataframe as dd\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dd ((403456, 8)) to parquet took 1.6464362144470215 seconds.\n",
      "Parquet file size 16.595705 MB\n"
     ]
    }
   ],
   "source": [
    "px_dd = dd.from_pandas(tech_dt, npartitions = len(tech_tickers))\n",
    "parquet_path = os.path.join(temp, \"stock_px.parquet\")\n",
    "\n",
    "start = time.time()\n",
    "px_dd.to_parquet(parquet_path, engine = \"pyarrow\")\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing dd ({tech_dt.shape}) to parquet took {end - start} seconds.')\n",
    "print(f'Parquet file size { get_dir_size(parquet_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet files and Dask Dataframes\n",
    "\n",
    "+ Parquet files are immutable: once written, they cannot be modified.\n",
    "+ Dask DataFrames are a useful implementation to manipulate data stored in parquets.\n",
    "+ Parquet and Dask are not the same: parquet is a file format that can be accessed by many applications and programming languages (Python, R, PowerBI, etc.), while Dask is a package in Python to work with large datasets using distributed computation.\n",
    "+ **Dask is not for everything** (see [Dask DataFrames Best Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html)). \n",
    "\n",
    "    - Consider cases suchas small to large joins, where the small dataframe fits in memory, but the large one does not. \n",
    "    - If possible, use pandas: reduce, then use pandas.\n",
    "    - Pandas performance tips apply to Dask.\n",
    "    - Use the index: it is beneficial to have a well-defined index in Dask DataFrames, as it may speed up searching (filtering) the data. A one-dimensional index is allowed.\n",
    "    - Avoid (or minimize) full-data shuffling: indexing is an expensive operations. \n",
    "    - Some joins are more expensive than others. \n",
    "\n",
    "        * Not expensive:\n",
    "\n",
    "            - Join a Dask DataFrame with a pandas DataFrame.\n",
    "            - Join a Dask DataFrame with another Dask DataFrame of a single partition.\n",
    "            - Join Dask DataFrames along their indexes.\n",
    "\n",
    "        * Expensive:\n",
    "\n",
    "            - Join Dask DataFrames along columns that are not their index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we store prices?\n",
    "\n",
    "+ We can store our data as a single blob. This can be difficult to maintain, especially because parquet files are immutable.\n",
    "+ Strategy: organize data files by ticker and date. Update only latest month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "import shutil\n",
    "if os.path.exists(PRICE_DATA):\n",
    "    shutil.rmtree(PRICE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tech_dt['Ticker'].unique():\n",
    "    ticker_dt = tech_dt[tech_dt['Ticker'] == ticker]\n",
    "    ticker_dt = ticker_dt.assign(Year = ticker_dt.Date.dt.year)\n",
    "    for yr in ticker_dt['Year'].unique():\n",
    "        yr_dd = dd.from_pandas(ticker_dt[ticker_dt['Year'] == yr],2)\n",
    "        yr_path = os.path.join(PRICE_DATA, ticker, f\"{ticker}_{yr}\")\n",
    "        os.makedirs(os.path.dirname(yr_path), exist_ok=True)\n",
    "        yr_dd.to_parquet(yr_path, engine = \"pyarrow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to store data this way?\n",
    "\n",
    "+ Easier to maintain. We do not update old data, only recent data.\n",
    "+ We can also access all files as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Transform and Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "+ Parquet files can be read individually or as a collection.\n",
    "+ `dd.read_parquet()` can take a list (collection) of files as input.\n",
    "+ Use `glob` to get the collection of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"**/*.parquet\"), recursive = True)\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"Ticker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "+ This transformation step will create a *Features* data set. In our case, features will be stock returns (we obtained prices).\n",
    "+ Dask dataframes work like pandas dataframes: in particular, we can perform groupby and apply operations.\n",
    "+ Notice the use of [an anonymous (lambda) function](https://realpython.com/python-lambda/) in the apply statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyunh\\AppData\\Local\\Temp\\ipykernel_19248\\3086392435.py:1: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_shift = dd_px.groupby('Ticker', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "dd_shift = dd_px.groupby('Ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets = dd_shift.assign(\n",
    "    Returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Exection\n",
    "\n",
    "What does `dd_rets` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=64</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int32</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 14 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                               Date Adj Close    Close     High      Low     Open   Volume   Year Close_lag_1  Returns\n",
       "npartitions=64                                                                                                        \n",
       "AAPL            datetime64[ns, UTC]   float64  float64  float64  float64  float64  float64  int32     float64  float64\n",
       "ACN                             ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "...                             ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "ZBRA                            ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "ZBRA                            ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "Dask Name: assign, 14 graph layers"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dask is a lazy execution framework: commands will not execute until they are required. \n",
    "+ To trigger an execution in dask use `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>535796800.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-04 00:00:00+00:00</td>\n",
       "      <td>0.771996</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.987723</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>512377600.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>-0.084310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-05 00:00:00+00:00</td>\n",
       "      <td>0.783293</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>778321600.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.014633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-06 00:00:00+00:00</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>767972800.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-0.086538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-07 00:00:00+00:00</td>\n",
       "      <td>0.749401</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>460734400.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.047369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-17 00:00:00+00:00</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>407.290009</td>\n",
       "      <td>402.290009</td>\n",
       "      <td>406.040009</td>\n",
       "      <td>270600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>402.720001</td>\n",
       "      <td>0.007424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-21 00:00:00+00:00</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>419.850006</td>\n",
       "      <td>407.619995</td>\n",
       "      <td>407.619995</td>\n",
       "      <td>446000.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>0.030465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-22 00:00:00+00:00</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>427.760010</td>\n",
       "      <td>419.589996</td>\n",
       "      <td>425.239990</td>\n",
       "      <td>497500.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>0.005980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-23 00:00:00+00:00</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>422.290009</td>\n",
       "      <td>414.450012</td>\n",
       "      <td>417.619995</td>\n",
       "      <td>377100.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>420.079987</td>\n",
       "      <td>413.739990</td>\n",
       "      <td>419.059998</td>\n",
       "      <td>258900.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>-0.015435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403456 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date   Adj Close       Close        High  \\\n",
       "Ticker                                                                 \n",
       "AAPL   2000-01-03 00:00:00+00:00    0.843077    0.999442    1.004464   \n",
       "AAPL   2000-01-04 00:00:00+00:00    0.771996    0.915179    0.987723   \n",
       "AAPL   2000-01-05 00:00:00+00:00    0.783293    0.928571    0.987165   \n",
       "AAPL   2000-01-06 00:00:00+00:00    0.715509    0.848214    0.955357   \n",
       "AAPL   2000-01-07 00:00:00+00:00    0.749401    0.888393    0.901786   \n",
       "...                          ...         ...         ...         ...   \n",
       "ZBRA   2025-01-17 00:00:00+00:00  405.709991  405.709991  407.290009   \n",
       "ZBRA   2025-01-21 00:00:00+00:00  418.070007  418.070007  419.850006   \n",
       "ZBRA   2025-01-22 00:00:00+00:00  420.570007  420.570007  427.760010   \n",
       "ZBRA   2025-01-23 00:00:00+00:00  421.109985  421.109985  422.290009   \n",
       "ZBRA   2025-01-24 00:00:00+00:00  414.609985  414.609985  420.079987   \n",
       "\n",
       "               Low        Open       Volume  Year  Close_lag_1   Returns  \n",
       "Ticker                                                                    \n",
       "AAPL      0.907924    0.936384  535796800.0  2000          NaN       NaN  \n",
       "AAPL      0.903460    0.966518  512377600.0  2000     0.999442 -0.084310  \n",
       "AAPL      0.919643    0.926339  778321600.0  2000     0.915179  0.014633  \n",
       "AAPL      0.848214    0.947545  767972800.0  2000     0.928571 -0.086538  \n",
       "AAPL      0.852679    0.861607  460734400.0  2000     0.848214  0.047369  \n",
       "...            ...         ...          ...   ...          ...       ...  \n",
       "ZBRA    402.290009  406.040009     270600.0  2025   402.720001  0.007424  \n",
       "ZBRA    407.619995  407.619995     446000.0  2025   405.709991  0.030465  \n",
       "ZBRA    419.589996  425.239990     497500.0  2025   418.070007  0.005980  \n",
       "ZBRA    414.450012  417.619995     377100.0  2025   420.570007  0.001284  \n",
       "ZBRA    413.739990  419.059998     258900.0  2025   421.109985 -0.015435  \n",
       "\n",
       "[403456 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rets.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "+ Apply transformations to calculate daily returns\n",
    "+ Store the enriched data, the silver dataset, in a new directory.\n",
    "+ Should we keep the same namespace? All columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before save\n",
    "FEATURES_DATA = os.getenv(\"FEATURES_DATA\")\n",
    "if os.path.exists(FEATURES_DATA):\n",
    "    shutil.rmtree(FEATURES_DATA)\n",
    "dd_rets.to_parquet(FEATURES_DATA, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: from Jupyter to Command Line\n",
    "\n",
    "+ We have drafted our code in a Jupyter Notebook. \n",
    "+ Finalized code should be written in Python modules.\n",
    "\n",
    "## Object Oriented vs Functional Programming\n",
    "\n",
    "+ We can use classes to keep parameters and functions together.\n",
    "+ We *could* use Object Oriented Programming, but parallelization of data manipulation and modelling tasks benefit from *Functional Programming*.\n",
    "+ An Idea: \n",
    "\n",
    "    - [Data Oriented Programming](https://blog.klipse.tech/dop/2022/06/22/principles-of-dop.html).\n",
    "    - Use the class to bundle together parameters and functions.\n",
    "    - Use stateless operations and treat all data objects as immutable (we do not modify them, we overwrite them).\n",
    "    - Take advantage of [`@staticmethod`](https://realpython.com/instance-class-and-static-methods-demystified/).\n",
    "\n",
    "The code is in `./05_src/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original design was:\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataManager` class in `./05_src/data_manager.py` is a simple implementation of the ideas and code discussed in this notebook. The lines below will download data for about 500 stocks from the S&P500. Using this data a few features will be created and stored in the features data set.\n",
    "\n",
    "First, instantiate an object of class `DataManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.download_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add features to the data set and save to a *feature store*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.featurize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
